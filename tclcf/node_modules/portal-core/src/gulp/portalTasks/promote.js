module.exports = function(gulp, config, done) {
    var AWS = require('aws-sdk')
    var awspublish = require('gulp-awspublish')
    var path = require('path')
    var fs = require('fs-extra')
    var gutil = require('gulp-util')
    var _ = require('lodash')
    var args = require('minimist')

    // Set up shared variables
    var index
    var filter
    var files
    var base = `${path.resolve(config.promote.cache)}/`
    var project = fs.readJsonSync('./package.json')


    var accessKeyId = process.env.AWS_ACCESS_KEY
    var secretAccessKey = process.env.AWS_SECRET_KEY

    var target = args(process.argv.slice(2)).target
    var targetLocation = _.indexOf(config.promote.environments, target)

    if (!targetLocation || targetLocation <= 0) {
        gutil.log(gutil.colors.red(`cannot promote. ${target} is not a valid target environment`))
        return
    }

    var source = config.promote.environments[targetLocation - 1]
    var bucket = `${project.name}-${source}.connectedfleet.io`
    var promotedBucket = `${project.name}-${target}.connectedfleet.io`

    var s3 = new AWS.S3({
        accessKeyId: accessKeyId,
        secretAccessKey: secretAccessKey
    })

    var sourceParams = {
        Bucket: bucket
    }

    // Private asynchronous methods
    var findHash = function(callback) {
        s3.getBucketWebsite(sourceParams, function(err, data) {
            if (err) {
                gutil.log(gutil.colors.red(err), err)
            }

            index = data.IndexDocument.Suffix
            var tokens = index.split('.')
            filter = tokens[1]
            gutil.log(gutil.colors.yellow('Promoting SHA:'), filter)
            callback()
        })
    }

    function uploadFile(key) {
        var publisher = awspublish.create({
            params: {
                Bucket: promotedBucket
            },
            accessKeyId: accessKeyId,
            secretAccessKey: secretAccessKey
        })

        gulp.src(base + key, {base: base})
            .pipe(publisher.publish([], {options: {force: true}}))
            .pipe(publisher.publish())
            .pipe(awspublish.reporter())
    }

    var getFilenames = function(callBack) {
        s3.listObjects(sourceParams, function(err, data) {
            if (err) {
                gutil.log(gutil.colors.red(err), err)
            } else {
                // Find all the keys (files) with the appropriate hash
                files = _.filter(_.map(data.Contents, 'Key'), function(key) {
                    return _.includes(key, filter) || key === 'favicon.ico'
                })
                callBack()
            }
        })
    }

    var processFile = function(filename) {
        var file = fs.createOutputStream(`${config.promote.cache}/${filename}`)
        var readStream = s3.getObject({
            Key: filename, Bucket: bucket
        }).createReadStream()

        readStream.pipe(file)

        file.on('close', function() {
            uploadFile(filename)
        })

    }

    var processFilenames = function() {
        _.each(files, function(file) {
            gutil.log(gutil.colors.blue(`downloading file: ${file}`))
            processFile(file)
        })
    }

    var updatePromotedIndex = function() {
        // Update next Bucket
        var indexFile = `index.${filter}.html`
        gutil.log(gutil.colors.yellow(`Updating ${promotedBucket} to use index file: ${indexFile}`))

        var params = {
            Bucket: promotedBucket,
            WebsiteConfiguration: {
                IndexDocument: {
                    Suffix: indexFile
                }
            }
        }

        s3.putBucketWebsite(params, function(err) {
            if (err) {
                gutil.log(gutil.colors.red(err), err)
            }
        })
    }

    // Chain everything together
    var postHash = function() {
        getFilenames(processFilenames)
        updatePromotedIndex()
    }

    findHash(postHash)

    done()
}
